{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29452d65",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Building a Sentiment Classifier with Logistic Regression\n",
    "\n",
    "In this notebook, we will build a **Logistic Regression** classifier to predict the sentiment (positive or negative) of customer reviews for women's clothing from an e-commerce website. \n",
    "\n",
    "For this task, we will use the **LogisticRegression** class from the scikit-learn library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9559ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e926ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the dataset.\n",
      "Dataset preview:\n",
      "                                         Review Text  sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...          1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
      "3  This shirt is very flattering to all due to th...          1\n",
      "4  I love tracy reese dresses, but this one is no...         -1\n"
     ]
    }
   ],
   "source": [
    "file_path = 'womens_clothing_ecommerce_reviews.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Successfully loaded the dataset.\")\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae245ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19818 entries, 0 to 19817\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review Text  19818 non-null  object\n",
      " 1   sentiment    19818 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 309.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get some basic information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd91bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into 15854 training samples and 3964 testing samples.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split Data into Training and Testing Sets ---\n",
    "# It's crucial to test our model on data it has never seen before.\n",
    "# We'll use 80% of the data for training and 20% for testing.\n",
    "X = df['Review Text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 'stratify=y' ensures that the proportion of positive and negative reviews is the same in both your training set and your testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nData split into {len(X_train)} training samples and {len(X_test)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b752e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting text to numerical features using Bag-of-Words...\n",
      "X_train_bow Shape:\n",
      " (15854, 11897)\n",
      "Unique words (features): ['00' '000' '00p' ... 'zooming' 'zuma' 'Ã£Â¼ber']\n",
      "X_train_bow:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 373991 stored elements and shape (15854, 11897)>\n",
      "  Coords\tValues\n",
      "  (0, 10214)\t1\n",
      "  (0, 2396)\t1\n",
      "  (0, 4805)\t1\n",
      "  (0, 4210)\t1\n",
      "  (0, 3835)\t1\n",
      "  (0, 9289)\t1\n",
      "  (0, 3680)\t1\n",
      "  (0, 4669)\t1\n",
      "  (0, 6980)\t1\n",
      "  (0, 10773)\t1\n",
      "  (0, 7248)\t1\n",
      "  (0, 7409)\t1\n",
      "  (1, 9289)\t1\n",
      "  (1, 2866)\t1\n",
      "  (1, 3454)\t1\n",
      "  (1, 4206)\t1\n",
      "  (1, 1781)\t1\n",
      "  (1, 6221)\t1\n",
      "  (1, 6711)\t1\n",
      "  (1, 8861)\t1\n",
      "  (1, 9671)\t1\n",
      "  (1, 9424)\t1\n",
      "  (1, 11)\t1\n",
      "  (2, 7409)\t1\n",
      "  (2, 3454)\t3\n",
      "  :\t:\n",
      "  (15853, 4805)\t1\n",
      "  (15853, 7596)\t1\n",
      "  (15853, 6257)\t1\n",
      "  (15853, 2390)\t1\n",
      "  (15853, 11495)\t1\n",
      "  (15853, 1602)\t1\n",
      "  (15853, 8053)\t1\n",
      "  (15853, 4742)\t1\n",
      "  (15853, 8467)\t1\n",
      "  (15853, 7829)\t1\n",
      "  (15853, 9466)\t1\n",
      "  (15853, 10594)\t1\n",
      "  (15853, 11408)\t1\n",
      "  (15853, 11414)\t1\n",
      "  (15853, 8195)\t1\n",
      "  (15853, 584)\t1\n",
      "  (15853, 11438)\t1\n",
      "  (15853, 5070)\t1\n",
      "  (15853, 11519)\t1\n",
      "  (15853, 9280)\t1\n",
      "  (15853, 9273)\t1\n",
      "  (15853, 5103)\t1\n",
      "  (15853, 3990)\t1\n",
      "  (15853, 521)\t1\n",
      "  (15853, 4857)\t1\n",
      "âœ… Text successfully converted to feature vectors.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Feature Engineering with Bag-of-Words ---\n",
    "# Here, we convert the text reviews into numerical feature vectors.\n",
    "# Each feature is a count of how many times a word appears in a review.\n",
    "print(\"\\nConverting text to numerical features using Bag-of-Words...\")\n",
    "\n",
    "# Initialize the vectorizer. `stop_words='english'` removes common\n",
    "# English words like 'the', 'a', 'is', which don't carry much sentiment.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the TRAINING data and transform it into a matrix\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "print(f\"X_train_bow Shape:\\n {X_train_bow.shape}\")\n",
    "\n",
    "print(f\"Unique words (features): {vectorizer.get_feature_names_out()}\")\n",
    "\n",
    "# Output is a sparse matrix representation, where most entries are zero and only non-zero values are stored\n",
    "print(f\"X_train_bow:\\n {X_train_bow}\")\n",
    "\n",
    "# ONLY transform the TESTING data using the already-fitted vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"âœ… Text successfully converted to feature vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22202e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Logistic Regression model...\n",
      "âœ… Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Train the Linear Classifier ---\n",
    "# We'll use Logistic Regression, a reliable linear model for classification.\n",
    "print(\"\\nTraining the Logistic Regression model...\")\n",
    "\n",
    "# Initialize the model\n",
    "# max_iter is increased to ensure the model has enough time to find the best weights\n",
    "# solver: Algorithm for optimization (default: 'lbfgs'). Options: 'lbfgs', 'liblinear', 'saga', 'newton-cg', 'sag'\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
    "\n",
    "# Train the model on our Bag-of-Words training data\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "print(\"âœ… Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19a219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model performance on the test set...\n",
      "ðŸ“ˆ Model Accuracy: 0.9299 (92.99%)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Evaluate the Model's Performance ---\n",
    "# Let's see how accurately our model predicts sentiment on the unseen test data.\n",
    "print(\"\\nEvaluating model performance on the test set...\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_bow)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ðŸ“ˆ Model Accuracy: {accuracy:.4f} ({accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af6b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to save the model\n",
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22b3a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the vectorizer file\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aefb069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Making Predictions on New Reviews ---\n",
      "new_reviews_bow shape: (5, 11897)\n",
      "<class 'numpy.ndarray'>\n",
      "[ 1 -1 -1 -1  1]\n",
      "Review: This dress is absolutely beautiful and fits perfectly!\n",
      "Predicted Sentiment: 1\n",
      "\n",
      "Review: The material felt cheap and it was not what I expected.\n",
      "Predicted Sentiment: -1\n",
      "\n",
      "Review: It's an okay product, not great but not terrible either.\n",
      "Predicted Sentiment: -1\n",
      "\n",
      "Review: I am so disappointed with this purchase, I will be returning it.\n",
      "Predicted Sentiment: -1\n",
      "\n",
      "Review: I want to buy this again and again!\n",
      "Predicted Sentiment: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Predict Sentiment on New Reviews ---\n",
    "# This is the fun part! Let's use our fine-tuned model on brand new text.\n",
    "print(\"\\n--- Making Predictions on New Reviews ---\")\n",
    "\n",
    "new_reviews = [\n",
    "    \"This dress is absolutely beautiful and fits perfectly!\",\n",
    "    \"The material felt cheap and it was not what I expected.\",\n",
    "    \"It's an okay product, not great but not terrible either.\",\n",
    "    \"I am so disappointed with this purchase, I will be returning it.\",\n",
    "    \"I want to buy this again and again!\",\n",
    "]\n",
    "\n",
    "# 1. Transform the new reviews into the Bag-of-Words format\n",
    "new_reviews_bow = vectorizer.transform(new_reviews)\n",
    "print(\"new_reviews_bow shape:\", new_reviews_bow.shape)\n",
    "\n",
    "# 2. Predict using our trained model\n",
    "new_predictions = model.predict(new_reviews_bow)\n",
    "\n",
    "print(type(new_predictions))\n",
    "print(new_predictions)\n",
    "\n",
    "\n",
    "for i in range(len(new_reviews)):\n",
    "    print(f\"Review: {new_reviews[i]}\")\n",
    "    print(f\"Predicted Sentiment: {new_predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602db39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
